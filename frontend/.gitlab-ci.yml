cache:
  paths:
    - frontend/dist/frontend

variables:
  VERSION: 1.0.${CI_PIPELINE_ID}
  MAVEN_REPO_PATH: "${CI_PROJECT_DIR}/.m2/repository"

stages:
  - build
  - release
  - test
  - deploy

build:
  stage: build
  image:
    name: gcr.io/kaniko-project/executor:v1.9.0-debug
    entrypoint: [""]
  script:
    - /kaniko/executor
      --context "${CI_PROJECT_DIR}/frontend"
      --dockerfile "${CI_PROJECT_DIR}/frontend/Dockerfile"
      --destination "${CI_REGISTRY_IMAGE}/frontend:$CI_COMMIT_SHA"
      --build-arg VERSION=$VERSION
      --cache=true

release:
  variables:
    GIT_STRATEGY: none
  image:
    name: gcr.io/go-containerregistry/crane:debug
    entrypoint: [""]
  cache: []
  stage: release
  before_script:
    - crane auth login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - crane tag $CI_REGISTRY_IMAGE/frontend:$CI_COMMIT_SHA $VERSION

test:
  stage: test
  image:
    name: sonarsource/sonar-scanner-cli:latest
    entrypoint: [""]
  variables:
    SONAR_USER_HOME: "${CI_PROJECT_DIR}/.sonar"
    GIT_DEPTH: "0"
  cache:
    key: "${CI_COMMIT_REF_SLUG}-${CI_JOB_NAME}"
    paths:
      - .sonar/cache
  script:
    - sonar-scanner -Dsonar.qualitygate.wait=true -Dsonar.projectKey=${SONAR_PROJECT_KEY_FRONTEND} -Dsonar.sources=frontend/ -Dsonar.host.url=${SONARQUBE_URL} -Dsonar.login=${SONAR_LOGIN_FRONTEND}
  allow_failure: true

# Стадия актуальна для деплоя docker контейнеров
# deploy:
#   stage: deploy
#   image: alpine:3.18
#   before_script:
#     - apk add openssh-client bash gettext
#     - eval $(ssh-agent -s)
#     - echo "${SSH_PRIVATE_KEY}" | tr -d '\r' | ssh-add -
#     - mkdir -p ~/.ssh
#     - chmod 700 ~/.ssh
#     - echo "$SSH_KNOWN_HOSTS" >> ~/.ssh/known_hosts
#     - chmod 644 ~/.ssh/known_hosts
#     - ssh-keygen -R ${DEV_HOST}
#     - ssh -o StrictHostKeyChecking=no ${DEV_USER}@${DEV_HOST} "mkdir -p /tmp/${CI_PROJECT_DIR}/frontend/"
#     - envsubst < ./frontend/deploy.sh|ssh ${DEV_USER}@${DEV_HOST}
#   script:
#     - echo "Deployment step is complete"

deploy:
  stage: deploy
  image: alpine/k8s:1.28.14
  environment:
    name: Kubernetes/frontend
    url: http://vm.momo-store.cloud-ip.biz
  only:
    changes:
      - kubernetes/frontend/**/*
      - frontend/**/*
  before_script:
    - curl -sSL https://storage.yandexcloud.net/yandexcloud-yc/install.sh | bash
    - sudo ln -s yandex-cloud/bin/yc /usr/bin/yc
    - pwd
    - ls -la
    - ls -la yandex-cloud
    - yc config profile create momo-alex
    - yc config set token ${TOKEN} --profile momo-alex
    - yc config set folder-id ${FOLDER_ID} --profile momo-alex
    - yc config set cloud-id ${CLOUD_ID} --profile momo-alex
  script:
    - curl -sSL https://storage.yandexcloud.net/yandexcloud-yc/install.sh | bash
    - pwd
    - ls -la yandex-cloud
    - mkdir -p .kube
    # - cp ~/.kube/config ~/.kube/config.backup
    - echo "$KUBECONFIG_BASE64"
    - echo "$KUBECONFIG_BASE64" | base64 -d > .kube/config
    - export KUBECONFIG=.kube/config
    - ls -la .kube/config
    - cat .kube/config
    - envsubst < kubernetes/frontend/configmap.yaml | kubectl apply -f -
    - envsubst < kubernetes/frontend/secrets.yaml | kubectl apply -f -
    - envsubst < kubernetes/frontend/deployment.yaml | kubectl apply -f -
    - envsubst < kubernetes/frontend/service.yaml | kubectl apply -f -
    - envsubst < kubernetes/frontend/ingress.yaml | kubectl apply -f -
  after_script:
    - rm -f ~/.kube/config
